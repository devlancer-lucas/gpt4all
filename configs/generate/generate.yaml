# model/tokenizer
model_name: # REPLACE HERE with the base llama model 
tokenizer_name: # REPLACE HERE with the llama tokenizer
lora: true
lora_path: "nomic-ai/gpt4all-lora"

max_new_tokens: 512
temperature: 0
prompt: | 
  #this code prints a string reversed
  my_string = "hello how are you"
  print(len(my_string))


  My code above does not work. Can you help me?
