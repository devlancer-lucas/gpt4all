# model/tokenizer
model_name: "zpn/llama-7b"
tokenizer_name: "zpn/llama-7b"
lora: true
lora_path: "nomic-ai/vicuna-lora-512"

max_new_tokens: 512
temperature: 0