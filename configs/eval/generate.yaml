# model/tokenizer
model_name: # update with llama 7b 
tokenizer_name: # update with llama 7b
lora: true
lora_path: "nomic-ai/gpt4all-lora"

max_new_tokens: 512
temperature: 0.001
prompt: | 
  #this code prints a string reversed
  my_string = "hello how are you"
  print(len(my_string))


  My code above does not work. Can you help me?
